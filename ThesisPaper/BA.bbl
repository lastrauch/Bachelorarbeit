\begin{thebibliography}{10}

\bibitem{tensorflow}
Mart\'{\i}n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
  Craig Citro, Greg~S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin,
  Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
  Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
  Levenberg, Dandelion Man\'{e}, Rajat Monga, Sherry Moore, Derek Murray, Chris
  Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal
  Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\'{e}gas,
  Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and
  Xiaoqiang Zheng.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock Software available from tensorflow.org.

\bibitem{feedforward}
David~H. Ackley, Geoffrey~E. Hinton, and Terrence~J. Sejnowski.
\newblock A learning algorithm for boltzmann machines*.
\newblock {\em Cognitive Science}, 9(1):147--169, 1985.

\bibitem{infor}
Ricardo Baeza-Yates.
\newblock {\em Modern information retrieval}.
\newblock ACM Press books. New York, NY : ACM Press : Addison-Wesley, New York,
  NY, [nachdr.] edition, 2002.

\bibitem{btheory}
Mr. Bayes and Mr. Price.
\newblock An essay towards solving a problem in the doctrine of chances. by the
  late rev. mr. bayes, f. r. s. communicated by mr. price, in a letter to john
  canton, a. m. f. r. s.
\newblock {\em Philosophical Transactions (1683-1775)}, 53:370--418, 1763.

\bibitem{neural}
Yoshua Bengio, R{\'e}jean Ducharme, Pascal Vincent, and Christian Janvin.
\newblock A neural probabilistic language model.
\newblock {\em J. Mach. Learn. Res.}, 3:1137--1155, March 2003.

\bibitem{fasttext}
Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov.
\newblock Enriching word vectors with subword information.
\newblock {\em arXiv preprint arXiv:1607.04606}, 2016.

\bibitem{algorithms}
Giuseppe Bonaccorso.
\newblock {\em Machine learning algorithms : reference guide for popular
  algorithms for data science and machine learning}.
\newblock Birmingham, England ; Mumbai, India : Packt, 2017.

\bibitem{algorithms2}
Giuseppe Bonaccorso.
\newblock {\em Machine learning algorithms : popular algorithms for data
  science and machine learning}.
\newblock Birmingham ; Mumbai : Packt Publishing, 2018.

\bibitem{randomforest}
Leo Breiman.
\newblock Random forests.
\newblock {\em Mach. Learn.}, 45(1):5--32, October 2001.

\bibitem{use}
Daniel Cer, Yinfei Yang, Sheng{-}yi Kong, Nan Hua, Nicole Limtiaco, Rhomni~St.
  John, Noah Constant, Mario Guajardo{-}Cespedes, Steve Yuan, Chris Tar,
  Yun{-}Hsuan Sung, Brian Strope, and Ray Kurzweil.
\newblock Universal sentence encoder.
\newblock {\em CoRR}, abs/1803.11175, 2018.

\bibitem{encodedecode}
Kyunghyun Cho, Bart van Merrienboer, {\c{C}}aglar G{\"{u}}l{\c{c}}ehre, Fethi
  Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using {RNN} encoder-decoder for
  statistical machine translation.
\newblock {\em CoRR}, abs/1406.1078, 2014.

\bibitem{IR-book}
Prabhakar~Raghavan Christopher D.~Manning and Hinrich Schütze.
\newblock {\em Introduction to Information Retrieval}.
\newblock Cambridge University Press., 2008.

\bibitem{pre1}
Alexis Conneau, Douwe Kiela, Holger Schwenk, Lo{\"{\i}}c Barrault, and Antoine
  Bordes.
\newblock Supervised learning of universal sentence representations from
  natural language inference data.
\newblock {\em CoRR}, abs/1705.02364, 2017.

\bibitem{bert}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em CoRR}, abs/1810.04805, 2018.

\bibitem{adam}
Jimmy~Ba Diederik P.~Kingma.
\newblock Adam: A method for stochastic optimization.
\newblock {\em CoRR}, abs/1412.6980, 2014.

\bibitem{bertgruppe}
Mehdi Drissi, Pedro Sandoval~Segura, Vivaswat Ojha, and Julie Medero.
\newblock Harvey mudd college at {S}em{E}val-2019 task 4: The clint buchanan
  hyperpartisan news detector.
\newblock In {\em Proceedings of the 13th International Workshop on Semantic
  Evaluation}, pages 962--966, Minneapolis, Minnesota, USA, June 2019.
  Association for Computational Linguistics.

\bibitem{bahdnau}
Yoshua~Bengio Dzmitry~Bahdanau, Kyunghyun~Cho.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em CoRR}, 2014.

\bibitem{parse}
Elementree.
\newblock
  \url{https://github.com/python/cpython/blob/3.7/Lib/xml/etree/ElementTree.py}.

\bibitem{ELMAN1990179}
Jeffrey~L. Elman.
\newblock Finding structure in time.
\newblock {\em Cognitive Science}, 14(2):179 -- 211, 1990.

\bibitem{liblinear}
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
\newblock Liblinear: A library for large linear classification.
\newblock {\em J. Mach. Learn. Res.}, 9:1871--1874, June 2008.

\bibitem{study}
Knight Foundation.
\newblock An online experimental platform to assess trust in the media.
\newblock
  \url{https://knightfoundation.org/reports/an-online-experimental-platform-to-assess-trust-in-the-media},
  July 2018.

\bibitem{rnn}
Palash Goyal.
\newblock {\em Deep Learning for Natural Language Processing : Creating Neural
  Networks with Python}.
\newblock Berkeley, CA : Apress : Imprint: Apress, Berkeley, CA, 2018.

\bibitem{evaluationasaservice}
Allan Hanbury, Henning Müller, Krisztian Balog, Torben Brodt, Gordon~V.
  Cormack, Ivan Eggel, Tim Gollub, Frank Hopfgartner, Jayashree
  Kalpathy-Cramer, Noriko Kando, Anastasia Krithara, Jimmy Lin, Simon Mercer,
  and Martin Potthast.
\newblock Evaluation-as-a-service: Overview and outlook, 2015.

\bibitem{logisticregressionbook}
Frank~E. Harrell.
\newblock {\em Binary Logistic Regression}, pages 219--274.
\newblock Springer International Publishing, Cham, 2015.

\bibitem{distributionalhypothesis}
Zellig~S. Harris.
\newblock Distributional structure.
\newblock {\em WORD}, 10(2-3):146--162, 1954.

\bibitem{residualcon}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock {\em CoRR}, abs/1512.03385, 2015.

\bibitem{lstm}
Sepp Hochreiter and Jürgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9:1735--80, 12 1997.

\bibitem{textclassification}
Emmanouil Ikonomakis, Sotiris Kotsiantis, and V~Tampakas.
\newblock Text classification using machine learning techniques.
\newblock {\em WSEAS transactions on computers}, 4:966--974, 08 2005.

\bibitem{gewinner}
Ye~Jiang, Johann Petrak, Xingyi Song, Kalina Bontcheva, and Diana Maynard.
\newblock Team bertha von suttner at {S}em{E}val-2019 task 4: Hyperpartisan
  news detection using {ELM}o sentence representation convolutional network.
\newblock In {\em Proceedings of the 13th International Workshop on Semantic
  Evaluation}, pages 840--844, Minneapolis, Minnesota, USA, June 2019.
  Association for Computational Linguistics.

\bibitem{normalization}
Geoffrey E.~Hinton Jimmy Lei~Ba, Jamie Ryan~Kiros.
\newblock Layer normalization.
\newblock {\em CoRR}, abs/1607.06450, 2016.

\bibitem{word2vecdortmund}
Thorsten Joachims.
\newblock Text categorization with support vector machines: Learning with many
  relevant features.
\newblock Technical report, Universit\"a Dortmund, 1997.

\bibitem{multinomialnb}
Ashraf~M. Kibriya, Eibe Frank, Bernhard Pfahringer, and Geoffrey Holmes.
\newblock Multinomial naive bayes for text categorization revisited.
\newblock In Geoffrey~I. Webb and Xinghuo Yu, editors, {\em AI 2004: Advances
  in Artificial Intelligence}, pages 488--499, Berlin, Heidelberg, 2005.
  Springer Berlin Heidelberg.

\bibitem{hyperpartisannewsdetection}
Johannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh,
  David Corney, Benno Stein, and Martin Potthast.
\newblock {S}em{E}val-2019 task 4: Hyperpartisan news detection.
\newblock In {\em Proceedings of the 13th International Workshop on Semantic
  Evaluation}, pages 829--839, Minneapolis, Minnesota, USA, June 2019.
  Association for Computational Linguistics.

\bibitem{socialbots}
Sonja Kind, Marc Bovenschulte, Simone Ehrenberg-Silies, and Sebastian Weide.
\newblock Social bots.
\newblock {\em TAB}, 2017.

\bibitem{doc2vec}
Quoc~V. Le and Tomas Mikolov.
\newblock Distributed representations of sentences and documents.
\newblock {\em CoRR}, abs/1405.4053, 2014.

\bibitem{facebook}
Vladimir~Kropotov Lion~Gu and Fyodor Yarochkin.
\newblock The fake news machine how propagandists abuse the internet and
  manipulate the public.
\newblock {\em TrendLabs}, 2017.

\bibitem{lunong}
Minh{-}Thang Luong, Hieu Pham, and Christopher~D. Manning.
\newblock Effective approaches to attention-based neural machine translation.
\newblock {\em CoRR}, abs/1508.04025, 2015.

\bibitem{iterparse}
Class iterparse.
\newblock \url{https://lxml.de/api/lxml.etree.iterparse-class.html}.

\bibitem{pre2}
Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher.
\newblock Learned in translation: Contextualized word vectors.
\newblock {\em CoRR}, abs/1708.00107, 2017.

\bibitem{pandas}
Wes McKinney et~al.
\newblock Data structures for statistical computing in python.
\newblock In {\em Proceedings of the 9th Python in Science Conference}, volume
  445, pages 51--56. Austin, TX, 2010.

\bibitem{webster}
The real story of 'fake news'.
\newblock
  https://www.merriam-webster.com/words-at-play/the-real-story-of-fake-news.

\bibitem{rnnmodel}
Tomas Mikolov, Martin Karafi{\'a}t, Luk{\'a}s Burget, Jan~Honza Cernock{\'y},
  and Sanjeev Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In {\em INTERSPEECH}, 2010.

\bibitem{pytorch}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in {PyTorch}.
\newblock In {\em NIPS Autodiff Workshop}, 2017.

\bibitem{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock {Scikit-learn: Machine Learning in Python }.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{glove}
Jeffrey Pennington, Richard Socher, and Christopher~D. Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em EMNLP}, 2014.

\bibitem{elmo}
Matthew~E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock {\em CoRR}, abs/1802.05365, 2018.

\bibitem{tira}
Martin Potthast, Tim Gollub, Francisco Rangel, Paolo Rosso, Efstathios
  Stamatatos, and Benno Stein.
\newblock {Improving the Reproducibility of PAN's Shared Tasks: Plagiarism
  Detection, Author Identification, and Author Profiling}.
\newblock In Evangelos Kanoulas, Mihai Lupu, Paul Clough, Mark Sanderson, Mark
  Hall, Allan Hanbury, and Elaine Toms, editors, {\em Information Access
  Evaluation meets Multilinguality, Multimodality, and Visualization. 5th
  International Conference of the CLEF Initiative (CLEF 2014)}, pages 268--299,
  Berlin Heidelberg New York, September 2014. Springer.

\bibitem{gensim}
Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka.
\newblock {Software Framework for Topic Modelling with Large Corpora}.
\newblock In {\em {Proceedings of the LREC 2010 Workshop on New Challenges for
  NLP Frameworks}}, pages 45--50, Valletta, Malta, May 2010. ELRA.
\newblock \url{http://is.muni.cz/publication/884893/en}.

\bibitem{word2vecparam}
Xin Rong.
\newblock word2vec parameter learning explained.
\newblock {\em CoRR}, abs/1411.2738, 2014.

\bibitem{coderandomforest}
sklearn.ensemble.randomforestclassifier.
\newblock
  \url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/ensemble/forest.py#L758}.

\bibitem{tfidf}
sklearn.feature\_extraction.text.
\newblock
  \url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb5b2012412888b69e73d76f2df2b50b6/sklearn/feature_extraction/text.py}.

\bibitem{logisticregression}
sklearn.linear\_model.
\newblock
  \url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/linear_model/logistic.py#L1202}.

\bibitem{codegridsearch}
sklearn.model\_selection.gridsearchcv.
\newblock
  \url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/model_selection/_search.py#L828}.

\bibitem{codemulinomialnb}
sklearn.naive\_bayes.multinomialnb.
\newblock
  \url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/naive_bayes.py#L636}.

\bibitem{dopout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock {\em Journal of Machine Learning Research}, 15:1929--1958, 2014.

\bibitem{vernon}
Vertika Srivastava, Ankita Gupta, Divya Prakash, Sudeep~Kumar Sahoo, Rohit R.R,
  and Yeon~Hyang Kim.
\newblock Vernon-fenwick at {S}em{E}val-2019 task 4: Hyperpartisan news
  detection using lexical and semantic features.
\newblock In {\em Proceedings of the 13th International Workshop on Semantic
  Evaluation}, pages 1078--1082, Minneapolis, Minnesota, USA, June 2019.
  Association for Computational Linguistics.

\bibitem{confusionmatrix}
Stephen~V. Stehman.
\newblock Selecting and interpreting measures of thematic classification
  accuracy.
\newblock {\em Remote Sensing of Environment}, 62(1):77 -- 89, 1997.

\bibitem{nltk}
Ewan~Klein Steven~Bird and Edward Loper.
\newblock {\em Natural Language Processing with Python – Analyzing Text with
  the Natural Language Toolkit}.
\newblock O'Reilly Media, 2009.

\bibitem{pre3}
Sandeep Subramanian, Guillaume Lample, Eric~Michael Smith, Ludovic Denoyer,
  Marc'Aurelio Ranzato, and Y{-}Lan Boureau.
\newblock Multiple-attribute text style transfer.
\newblock {\em CoRR}, abs/1811.00552, 2018.

\bibitem{s2s}
Ilya Sutskever, Oriol Vinyals, and Quoc V.~Le.
\newblock Sequence to sequence learning with neural networks.
\newblock {\em Advances in Neural Information Processing Systems}, 4, 09 2014.

\bibitem{cloze}
Wilson~L. Taylor.
\newblock “cloze procedure”: A new tool for measuring readability.
\newblock {\em Journalism Bulletin}, 30(4):415--433, 1953.

\bibitem{wb1}
Greg~Corrado Tomas~Mikolov, Kai~Chen and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space.
\newblock {\em CoRR}, abs/1301.3781, 2013.

\bibitem{effiecientestimation}
Greg~Corrado Tomas~Mikolov, Kai~Chen and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space.
\newblock {\em arXiv.org}, January 2013.

\bibitem{attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em CoRR}, abs/1706.03762, 2017.

\end{thebibliography}
