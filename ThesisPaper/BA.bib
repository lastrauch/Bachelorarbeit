@article{scikit-learn,
	title={{Scikit-learn: Machine Learning in Python }},
	author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
	and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
	and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
	Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal={Journal of Machine Learning Research},
	volume={12},
	pages={2825--2830},
	year={2011}
}

@book{IR-book,
	author={Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze},
	title={Introduction to Information Retrieval},
	publisher={Cambridge University Press.},
	year={2008}
}
@book{nltk,
	author={Steven Bird, Ewan Klein and Edward Loper},
	title={Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit},
	publisher={O'Reilly Media},
	year={2009}
}
@article{effiecientestimation,
	author      = {Tomas Mikolov, Kai Chen, Greg Corrado and Jeffrey Dean.},
	title       = {Efficient Estimation of Word Representations in Vector Space},
	journal 	= {arXiv.org},
	year        = {2013},
	month		= {January}
}
@article{word2vecparam,
 	author    = {Xin Rong},
	title     = {word2vec Parameter Learning Explained},
	journal   = {CoRR},
	volume    = {abs/1411.2738},
	year      = {2014},
	url       = {http://arxiv.org/abs/1411.2738},
	archivePrefix = {arXiv},
	eprint    = {1411.2738},
	timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/Rong14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{algorithms,
	author ={Bonaccorso, Giuseppe},
	title ={Machine learning algorithms : reference guide for popular algorithms for data science and machine learning},
	publisher ={Birmingham, England ; Mumbai, India : Packt},
	year ={2017}
}
@book{algorithms2,
	author ={Bonaccorso, Giuseppe},
	title ={Machine learning algorithms : popular algorithms for data science and machine learning},
	publisher ={Birmingham ; Mumbai : Packt Publishing},
	year ={2018}
}
@article{randomforest,
 	author = {Breiman, Leo},
	title = {Random Forests},
	journal = {Mach. Learn.},
	issue_date = {October 1 2001},
	volume = {45},
	number = {1},
	month = oct,
	year = {2001},
	issn = {0885-6125},
	pages = {5--32},
	numpages = {28},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	acmid = {570182},
	publisher = {Kluwer Academic Publishers},
	address = {Norwell, MA, USA},
	keywords = {classification, ensemble, regression},
}
@techreport{word2vecdortmund,
	author      = {Thorsten Joachims},
	title       = {Text Categorization with Support Vector Machines: Learning with Many Relevant Features},
	institution	= {Universit\"a Dortmund},
	year        = {1997},
}
@misc{parse,
	title = {ElemenTree},
	key={ElementTree},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/python/cpython/blob/3.7/Lib/xml/etree/ElementTree.py}}
}
@misc{iterparse,
	key={lxml},
	title = {Class iterparse},
	howpublished = {\url{https://lxml.de/api/lxml.etree.iterparse-class.html}}
}
@inproceedings{pandas, 
	title={Data structures for statistical computing in python}, 
	author={McKinney, Wes and others}, 
	booktitle={Proceedings of the 9th Python in Science Conference}, 
	volume={445}, 
	pages={51--56}, 
	year={2010}, 
	organization={Austin, TX} 
}
@article{textclassification,
	author = {Ikonomakis, Emmanouil and Kotsiantis, Sotiris and Tampakas, V},
	year = {2005},
	month = {08},
	pages = {966-974},
	title = {Text Classification Using Machine Learning Techniques},
	volume = {4},
	isbn = {1109-2750},
	journal = {WSEAS transactions on computers}
}
@misc{tfidf,
	title = {sklearn.feature\_extraction.text},
	key= {sklearn.feature\_extraction.text},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb5b2012412888b69e73d76f2df2b50b6/sklearn/feature_extraction/text.py}}
}
@inproceedings{gensim,
	title = {{Software Framework for Topic Modelling with Large Corpora}},
	author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
	booktitle = {{Proceedings of the LREC 2010 Workshop on New
	Challenges for NLP Frameworks}},
	pages = {45--50},
	year = 2010,
	month = May,
	day = 22,
	publisher = {ELRA},
	address = {Valletta, Malta},
	note={\url{http://is.muni.cz/publication/884893/en}},
	language={English}
}
@misc{logisticregression,
	title = {sklearn.linear\_model.},
	key= {sklearn.linear_model.},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/linear_model/logistic.py#L1202}}
}
@article{distributionalhypothesis,
	author = {Zellig S. Harris},
	title = {Distributional Structure},
	journal = {WORD},
	volume = {10},
	number = {2-3},
	pages = {146-162},
	year  = {1954},
	publisher = {Routledge},
	doi = {10.1080/00437956.1954.11659520},
	URL = { 
	https://doi.org/10.1080/00437956.1954.11659520},
	eprint = {https://doi.org/10.1080/00437956.1954.11659520}	
}
@article{confusionmatrix,
	title = "Selecting and interpreting measures of thematic classification accuracy",
	journal = "Remote Sensing of Environment",
	volume = "62",
	number = "1",
	pages = "77 - 89",
	year = "1997",
	issn = "0034-4257",
	doi = "https://doi.org/10.1016/S0034-4257(97)00083-7",
	url = "http://www.sciencedirect.com/science/article/pii/S0034425797000837",
	author = "Stephen V. Stehman",
}
@misc{codemulinomialnb,
	title = {sklearn.naive\_bayes.MultinomialNB},
	key= {sklearn.naive\_bayes.MultinomialNB},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/naive_bayes.py#L636}}
}
@misc{coderandomforest,
	title = {sklearn.ensemble.RandomForestClassifier},
	key= {sklearn.ensemble.RandomForestClassifier},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/ensemble/forest.py#L758}}
}
@misc{codegridsearch,
	title = {sklearn.model\_selection.GridSearchCV},
	key= {sklearn.model\_selection.GridSearchCV},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/scikit-learn/scikit-learn/blob/7813f7efb/sklearn/model_selection/_search.py#L828}}
}
@article{liblinear,
	author = {Fan, Rong-En and Chang, Kai-Wei and Hsieh, Cho-Jui and Wang, Xiang-Rui and Lin, Chih-Jen},
	title = {LIBLINEAR: A Library for Large Linear Classification},
	journal = {J. Mach. Learn. Res.},
	issue_date = {6/1/2008},
	volume = {9},
	month = jun,
	year = {2008},
	issn = {1532-4435},
	pages = {1871--1874},
	numpages = {4},
	url = {http://dl.acm.org/citation.cfm?id=1390681.1442794},
	acmid = {1442794},
	publisher = {JMLR.org},
} 
@misc{pickle,
	title = {pickle — Python object serialization},
	key= {pickle — Python object serialization},
	publisher = {Python},
	journal = {Python Documentation},
	howpublished = {\url{https://docs.python.org/3/library/pickle.html}}
}
@misc{keyedvectors,
	title = {models.keyedvectors – Store and query word vectors},
	key= {models.keyedvectors – Store and query word vectors},
	publisher = {gensim},
	journal = {gensim Documentation},
	howpublished = {\url{https://radimrehurek.com/gensim/models/keyedvectors.html}}
}
@InProceedings{multinomialnb,
	author="Kibriya, Ashraf M.
	and Frank, Eibe
	and Pfahringer, Bernhard
	and Holmes, Geoffrey",
	editor="Webb, Geoffrey I.
	and Yu, Xinghuo",
	title="Multinomial Naive Bayes for Text Categorization Revisited",
	booktitle="AI 2004: Advances in Artificial Intelligence",
	year="2005",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="488--499",
	abstract="This paper presents empirical results for several versions of the multinomial naive Bayes classifier on four text categorization problems, and a way of improving it using locally weighted learning. More specifically, it compares standard multinomial naive Bayes to the recently proposed transformed weight-normalized complement naive Bayes classifier (TWCNB) [1], and shows that some of the modifications included in TWCNB may not be necessary to achieve optimum performance on some datasets. However, it does show that TFIDF conversion and document length normalization are important. It also shows that support vector machines can, in fact, sometimes very significantly outperform both methods. Finally, it shows how the performance of multinomial naive Bayes can be improved using locally weighted learning. However, the overall conclusion of our paper is that support vector machines are still the method of choice if the aim is to maximize accuracy.",
	isbn="978-3-540-30549-1"
}
@article{btheory,
	ISSN = {02607085},
	URL = {http://www.jstor.org/stable/105741},
	author = {Mr. Bayes and Mr. Price},
	journal = {Philosophical Transactions (1683-1775)},
	pages = {370--418},
	publisher = {The Royal Society},
	title = {An Essay towards Solving a Problem in the Doctrine of Chances. By the Late Rev. Mr. Bayes, F. R. S. Communicated by Mr. Price, in a Letter to John Canton, A. M. F. R. S.},
	volume = {53},
	year = {1763}
}
@Inbook{logisticregressionbook,
	author="Harrell, Frank E.",
	title="Binary Logistic Regression",
	bookTitle="Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis",
	year="2015",
	publisher="Springer International Publishing",
	address="Cham",
	pages="219--274",
	abstract="Binary responses are commonly studied in many fields. Examples includeresponsebinary1 the presence or absence of a particular disease, death during surgery, or a consumer purchasing a product. Often one wishes to study how a set of predictor variables X is related to a dichotomous response variable Y. The predictors may describe such quantities as treatment assignment, dosage, risk factors, and calendar time. For convenience we define the response to be Y = 0 or 1, with Y = 1 denoting the occurrence of the event of interest. Often a dichotomous outcome can be studied by calculating certain proportions, for example, the proportion of deaths among females and the proportion among males. However, in many situations, there are multiple descriptors, or one or more of the descriptors are continuous. Without a statistical model, studying patterns such as the relationship between age and occurrence of a disease, for example, would require the creation of arbitrary age groups to allow estimation of disease prevalence as a function of age.",
	isbn="978-3-319-19425-7",
	doi="10.1007/978-3-319-19425-7_10",
	url="https://doi.org/10.1007/978-3-319-19425-7_10"
}
@article{bert,
	author    = {Jacob Devlin and
	Ming{-}Wei Chang and
	Kenton Lee and
	Kristina Toutanova},
	title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
	Understanding},
	journal   = {CoRR},
	volume    = {abs/1810.04805},
	year      = {2018},
	url       = {http://arxiv.org/abs/1810.04805},
	archivePrefix = {arXiv},
	eprint    = {1810.04805},
	timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-04805},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
}
@article{feedforward,
	author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
	title = {A Learning Algorithm for Boltzmann Machines*},
	journal = {Cognitive Science},
	volume = {9},
	number = {1},
	pages = {147-169},
	doi = {10.1207/s15516709cog0901\_7},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0901_7},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog0901_7},
	abstract = {The computational power of massively parallel networks of simple processing elements resides in the communication bandwidth provided by the hardware connections between elements. These connections can allow a significant fraction of the knowledge of the system to be applied to an instance of a problem in a very short time. One kind of computation for which massively parallel networks appear to be well suited is large constraint satisfaction searches, but to use the connections efficiently two conditions must be met: First, a search technique that is suitable for parallel networks must be found. Second, there must be some way of choosing internal representations which allow the preexisting hardware connections to be used efficiently for encoding the constraints in the domain being searched. We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connection strengths so as to incorporate knowledge about a task domain in an efficient way. We describe some simple examples in which the learning algorithm creates internal representations that are demonstrably the most efficient way of using the preexisting connectivity structure.},
	year = {1985}
}
@book{rnn,
	publisher = {Berkeley, CA : Apress : Imprint: Apress},
	isbn = {1484236858},
	year = {2018},
	title = {Deep Learning for Natural Language Processing : Creating Neural Networks with Python},
	language = {eng},
	address = {Berkeley, CA},
	author = {Goyal, Palash},
	keywords = {Artificial intelligence; Python (Computer program language); Open source software; Computer programming; Artificial Intelligence; Python; Open Source},
	abstract = {Discover the concepts of deep learning used for natural language processing (NLP), with full-fledged examples of neural network models such as recurrent neural networks, long short-term memory networks, and sequence-2-sequence models. You’ll start by covering the mathematical prerequisites and the fundamentals of deep learning and NLP with practical examples. The first three chapters of the book cover the basics of NLP, starting with word-vector representation before moving onto advanced algorithms. The final chapters focus entirely on implementation, and deal with sophisticated architectures such as RNN, LSTM, and Seq2seq, using Python tools: TensorFlow, and Keras. Deep Learning for Natural Language Processing follows a progressive approach and combines all the knowledge you have gained to build a question-answer chatbot system. This book is a good starting point for people who want to get started in deep learning for NLP. All the code presented in the book will be available in the form of IPython notebooks and scripts, which allow you to try out the examples and extend them in interesting ways. You will: Gain the fundamentals of deep learning and its mathematical prerequisites Discover deep learning frameworks in Python Develop a chatbot Implement a research paper on sentiment classification.}
}
@article{ELMAN1990179,
	title = "Finding structure in time",
	journal = "Cognitive Science",
	volume = "14",
	number = "2",
	pages = "179 - 211",
	year = "1990",
	issn = "0364-0213",
	doi = "https://doi.org/10.1016/0364-0213(90)90002-E",
	url = "http://www.sciencedirect.com/science/article/pii/036402139090002E",
	author = "Jeffrey L. Elman",
	abstract = "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
}
@inproceedings{rnnmodel,
	title={Recurrent neural network based language model},
	author={Tomas Mikolov and Martin Karafi{\'a}t and Luk{\'a}s Burget and Jan Honza Cernock{\'y} and Sanjeev Khudanpur},
	booktitle={INTERSPEECH},
	year={2010}
}
@article{lstm,
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	year = {1997},
	month = {12},
	pages = {1735-80},
	title = {Long Short-term Memory},
	volume = {9},
	journal = {Neural computation},
	doi = {10.1162/neco.1997.9.8.1735}
}
@article{encodedecode,
	author    = {Kyunghyun Cho and
	Bart van Merrienboer and
	{\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
	Fethi Bougares and
	Holger Schwenk and
	Yoshua Bengio},
	title     = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
	Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1406.1078},
	year      = {2014},
	url       = {http://arxiv.org/abs/1406.1078},
	archivePrefix = {arXiv},
	eprint    = {1406.1078},
	timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/ChoMGBSB14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{attention,
	author    = {Ashish Vaswani and
	Noam Shazeer and
	Niki Parmar and
	Jakob Uszkoreit and
	Llion Jones and
	Aidan N. Gomez and
	Lukasz Kaiser and
	Illia Polosukhin},
	title     = {Attention Is All You Need},
	journal   = {CoRR},
	volume    = {abs/1706.03762},
	year      = {2017},
	url       = {http://arxiv.org/abs/1706.03762},
	archivePrefix = {arXiv},
	eprint    = {1706.03762},
	timestamp = {Mon, 13 Aug 2018 16:48:37 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/VaswaniSPUJGKP17},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{lunong,
	author    = {Minh{-}Thang Luong and
	Hieu Pham and
	Christopher D. Manning},
	title     = {Effective Approaches to Attention-based Neural Machine Translation},
	journal   = {CoRR},
	volume    = {abs/1508.04025},
	year      = {2015},
	url       = {http://arxiv.org/abs/1508.04025},
	archivePrefix = {arXiv},
	eprint    = {1508.04025},
	timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/LuongPM15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{bahdnau,
	author    = {Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio},
	title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
	journal   = {CoRR},
	year      = {2014},
	url       = {https://arxiv.org/abs/1409.0473},
	archivePrefix = {arXiv},
	eprint    = {1508.04025}
}
@article{residualcon,
	author    = {Kaiming He and
	Xiangyu Zhang and
	Shaoqing Ren and
	Jian Sun},
	title     = {Deep Residual Learning for Image Recognition},
	journal   = {CoRR},
	volume    = {abs/1512.03385},
	year      = {2015},
	url       = {http://arxiv.org/abs/1512.03385},
	archivePrefix = {arXiv},
	eprint    = {1512.03385},
	timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{dopout,
	author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
	title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
	journal = {Journal of Machine Learning Research},
	year    = {2014},
	volume  = {15},
	pages   = {1929-1958},
	url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@article{normalization,
	author    = {Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton},
	title     = {Layer Normalization},
	journal   = {CoRR},
	volume    = {abs/1607.06450},
	year      = {2016},
	url       = {https://arxiv.org/abs/1607.06450},
	archivePrefix = {arXiv},
}
@article{cloze,
	author = {Wilson L. Taylor},
	title ={“Cloze Procedure”: A New Tool for Measuring Readability},
	journal = {Journalism Bulletin},
	volume = {30},
	number = {4},
	pages = {415-433},
	year = {1953},
	doi = {10.1177/107769905303000401},
	
	URL = { 
	https://doi.org/10.1177/107769905303000401
	
	},
	eprint = { 
	https://doi.org/10.1177/107769905303000401
	
	}
	,
	abstract = { Here is the first comprehensive statement of a research method and its theory which were introduced briefly during a workshop at the 1953 AEJ convention. Included are findings from three pilot studies and two experiments in which “cloze procedure” results are compared with those of two readability formulas. }
}
@misc{tensorflow,
	title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={https://www.tensorflow.org/},
	note={Software available from tensorflow.org},
	author={
	Mart\'{\i}n~Abadi and
	Ashish~Agarwal and
	Paul~Barham and
	Eugene~Brevdo and
	Zhifeng~Chen and
	Craig~Citro and
	Greg~S.~Corrado and
	Andy~Davis and
	Jeffrey~Dean and
	Matthieu~Devin and
	Sanjay~Ghemawat and
	Ian~Goodfellow and
	Andrew~Harp and
	Geoffrey~Irving and
	Michael~Isard and
	Yangqing Jia and
	Rafal~Jozefowicz and
	Lukasz~Kaiser and
	Manjunath~Kudlur and
	Josh~Levenberg and
	Dandelion~Man\'{e} and
	Rajat~Monga and
	Sherry~Moore and
	Derek~Murray and
	Chris~Olah and
	Mike~Schuster and
	Jonathon~Shlens and
	Benoit~Steiner and
	Ilya~Sutskever and
	Kunal~Talwar and
	Paul~Tucker and
	Vincent~Vanhoucke and
	Vijay~Vasudevan and
	Fernanda~Vi\'{e}gas and
	Oriol~Vinyals and
	Pete~Warden and
	Martin~Wattenberg and
	Martin~Wicke and
	Yuan~Yu and
	Xiaoqiang~Zheng},
	year={2015},
}
@inproceedings{pytorch,
	title={Automatic Differentiation in {PyTorch}},
	author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	booktitle={NIPS Autodiff Workshop},
	year={2017}
}
@article{adam,
	author    = {Diederik P. Kingma, Jimmy Ba},
	title     = {Adam: A Method for Stochastic Optimization},
	journal   = {CoRR},
	volume    = {abs/1412.6980 },
	year      = {2014},
	url       = {https://arxiv.org/abs/1412.6980},
	archivePrefix = {arXiv},
}
@article{fasttext,
	title={Enriching Word Vectors with Subword Information},
	author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
	journal={arXiv preprint arXiv:1607.04606},
	year={2016}
}
@inproceedings{glove,
	title={Glove: Global Vectors for Word Representation},
	author={Jeffrey Pennington and Richard Socher and Christopher D. Manning},
	booktitle={EMNLP},
	year={2014}
}
@article{elmo,
	author    = {Matthew E. Peters and
	Mark Neumann and
	Mohit Iyyer and
	Matt Gardner and
	Christopher Clark and
	Kenton Lee and
	Luke Zettlemoyer},
	title     = {Deep contextualized word representations},
	journal   = {CoRR},
	volume    = {abs/1802.05365},
	year      = {2018},
	url       = {http://arxiv.org/abs/1802.05365},
	archivePrefix = {arXiv},
	eprint    = {1802.05365},
	timestamp = {Mon, 13 Aug 2018 16:48:54 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1802-05365},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{gewinner,
	title = "Team Bertha von Suttner at {S}em{E}val-2019 Task 4: Hyperpartisan News Detection using {ELM}o Sentence Representation Convolutional Network",
	author = "Jiang, Ye  and
	Petrak, Johann  and
	Song, Xingyi  and
	Bontcheva, Kalina  and
	Maynard, Diana",
	booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota, USA",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/S19-2146",
	pages = "840--844",
	abstract = "This paper describes the participation of team {``}bertha-von-suttner{''} in the SemEval2019 task 4 Hyperpartisan News Detection task. Our system uses sentence representations from averaged word embeddings generated from the pre-trained ELMo model with Convolutional Neural Networks and Batch Normalization for predicting hyperpartisan news. The final predictions were generated from the averaged predictions of an ensemble of models. With this architecture, our system ranked in first place, based on accuracy, the official scoring metric.",
}
@inproceedings{vernon,
	title = "Vernon-fenwick at {S}em{E}val-2019 Task 4: Hyperpartisan News Detection using Lexical and Semantic Features",
	author = "Srivastava, Vertika  and
	Gupta, Ankita  and
	Prakash, Divya  and
	Sahoo, Sudeep Kumar  and
	R.R, Rohit  and
	Kim, Yeon Hyang",
	booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota, USA",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/S19-2189",
	pages = "1078--1082",
	abstract = "In this paper, we present our submission for SemEval-2019 Task 4: Hyperpartisan News Detection. Hyperpartisan news articles are sharply polarized and extremely biased (onesided). It shows blind beliefs, opinions and unreasonable adherence to a party, idea, faction or a person. Through this task, we aim to develop an automated system that can be used to detect hyperpartisan news and serve as a prescreening technique for fake news detection. The proposed system jointly uses a rich set of handcrafted textual and semantic features. Our system achieved 2nd rank on the primary metric (82.0{\%} accuracy) and 1st rank on the secondary metric (82.1{\%} F1-score), among all participating teams. Comparison with the best performing system on the leaderboard shows that our system is behind by only 0.2{\%} absolute difference in accuracy.",
}
@article{use,
	author    = {Daniel Cer and
	Yinfei Yang and
	Sheng{-}yi Kong and
	Nan Hua and
	Nicole Limtiaco and
	Rhomni St. John and
	Noah Constant and
	Mario Guajardo{-}Cespedes and
	Steve Yuan and
	Chris Tar and
	Yun{-}Hsuan Sung and
	Brian Strope and
	Ray Kurzweil},
	title     = {Universal Sentence Encoder},
	journal   = {CoRR},
	volume    = {abs/1803.11175},
	year      = {2018},
	url       = {http://arxiv.org/abs/1803.11175},
	archivePrefix = {arXiv},
	eprint    = {1803.11175},
	timestamp = {Mon, 13 Aug 2018 16:46:40 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1803-11175},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{doc2vec,
	author    = {Quoc V. Le and
	Tomas Mikolov},
	title     = {Distributed Representations of Sentences and Documents},
	journal   = {CoRR},
	volume    = {abs/1405.4053},
	year      = {2014},
	url       = {http://arxiv.org/abs/1405.4053},
	archivePrefix = {arXiv},
	eprint    = {1405.4053},
	timestamp = {Mon, 13 Aug 2018 16:48:49 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/LeM14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{bertgruppe,
	title = "Harvey Mudd College at {S}em{E}val-2019 Task 4: The Clint Buchanan Hyperpartisan News Detector",
	author = "Drissi, Mehdi  and
	Sandoval Segura, Pedro  and
	Ojha, Vivaswat  and
	Medero, Julie",
	booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota, USA",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/S19-2165",
	pages = "962--966",
	abstract = "We investigate the recently developed Bidi- rectional Encoder Representations from Transformers (BERT) model (Devlin et al. 2018) for the hyperpartisan news detection task. Using a subset of hand-labeled articles from SemEval as a validation set, we test the performance of different parameters for BERT models. We find that accuracy from two different BERT models using different proportions of the articles is consistently high, with our best-performing model on the validation set achieving 85{\%} accuracy and the best-performing model on the test set achieving 77{\%}. We further determined that our model exhibits strong consistency, labeling independent slices of the same article identically. Finally, we find that randomizing the order of word pieces dramatically reduces validation accuracy (to approximately 60{\%}), but that shuffling groups of four or more word pieces maintains an accuracy of about 80{\%}, indicating the model mainly gains value from local context.",
}
@inproceedings{hyperpartisannewsdetection,
	title = "{S}em{E}val-2019 Task 4: Hyperpartisan News Detection",
	author = "Kiesel, Johannes  and
	Mestre, Maria  and
	Shukla, Rishabh  and
	Vincent, Emmanuel  and
	Adineh, Payam  and
	Corney, David  and
	Stein, Benno  and
	Potthast, Martin",
	booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota, USA",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/S19-2145",
	pages = "829--839",
	abstract = "Hyperpartisan news is news that takes an extreme left-wing or right-wing standpoint. If one is able to reliably compute this meta information, news articles may be automatically tagged, this way encouraging or discouraging readers to consume the text. It is an open question how successfully hyperpartisan news detection can be automated, and the goal of this SemEval task was to shed light on the state of the art. We developed new resources for this purpose, including a manually labeled dataset with 1,273 articles, and a second dataset with 754,000 articles, labeled via distant supervision. The interest of the research community in our task exceeded all our expectations: The datasets were downloaded about 1,000 times, 322 teams registered, of which 184 configured a virtual machine on our shared task cloud service TIRA, of which in turn 42 teams submitted a valid run. The best team achieved an accuracy of 0.822 on a balanced sample (yes : no hyperpartisan) drawn from the manually tagged corpus; an ensemble of the submitted systems increased the accuracy by 0.048.",
}
@InProceedings{tira,
	address =             {Berlin Heidelberg New York},
	author =              {Martin Potthast and Tim Gollub and Francisco Rangel and Paolo Rosso and Efstathios Stamatatos and Benno Stein},
	booktitle =           {Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative (CLEF 2014)},
	doi =                 {10.1007/978-3-319-11382-1_22},
	editor =              {Evangelos Kanoulas and Mihai Lupu and Paul Clough and Mark Sanderson and Mark Hall and Allan Hanbury and Elaine Toms},
	isbn =                {978-3-319-11381-4},
	month =               sep,
	pages =               {268-299},
	publisher =           {Springer},
	title =               {{Improving the Reproducibility of PAN's Shared Tasks: Plagiarism Detection, Author Identification, and Author Profiling}},
	year =                2014
}
@misc{evaluationasaservice,
	title={Evaluation-as-a-Service: Overview and Outlook},
	author={Allan Hanbury and Henning Müller and Krisztian Balog and Torben Brodt and Gordon V. Cormack and Ivan Eggel and Tim Gollub and Frank Hopfgartner and Jayashree Kalpathy-Cramer and Noriko Kando and Anastasia Krithara and Jimmy Lin and Simon Mercer and Martin Potthast},
	year={2015},
	eprint={1512.07454},
	archivePrefix={arXiv},
	primaryClass={cs.CY}
}