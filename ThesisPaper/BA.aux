\relax 
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand \oddpage@label [2]{}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{BA.ist}
\@glsorder{word}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{locode}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem Statement}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contribution}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Related Work}{1}\protected@file@percent }
\citation{IR-book}
\citation{IR-book}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamentals}{2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{locode}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Term Frequency-Inverse Document Frequency}{2}\protected@file@percent }
\citation{distributionalhypothesis}
\citation{effiecientestimation}
\citation{word2vecparam}
\citation{word2vecparam}
\citation{word2vecparam}
\citation{word2vecparam}
\citation{word2vecparam}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Word Embeddings}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Word2Vec}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}SVM}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Multinomial Naive Bayes Classifier}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Logistic Regression Classifier}{4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces sigmoid function[Machine learning algorithms : reference guide for popular algorithms for data science and machine learning ]\relax }}{4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example}{{2.1}{4}}
\citation{algorithms}
\citation{algorithms}
\citation{algorithms}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Decision Trees and Random Forest Classifier}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Decision Trees}{6}\protected@file@percent }
\citation{randomforest}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Random Forest Classifier}{7}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Random Forest\relax }}{7}\protected@file@percent }
\citation{algorithms}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Cross Validation}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Evaluation}{8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Confusion Matrix\relax }}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Data}{10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{locode}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{cha:theory}{{3}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data Description}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Dataset labelled by Publisher}{11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Hyperpartisan Distribution by Publisher\relax }}{11}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Publishers with the highest proportion of Hypeprartisan articles\relax }}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Dataset labelled by Article}{11}\protected@file@percent }
\citation{parse}
\citation{iterparse}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Hyperpartisan Distribution by Article\relax }}{12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Publishing Years Distribution by Article\relax }}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data Preparation}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}File Parsing}{12}\protected@file@percent }
\citation{pandas}
\citation{textclassification}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Information Filtering}{13}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Parse Ground-Truth File\relax }}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Combine Data}{13}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Merge Groundtruth- and Trainingdatasets\relax }}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Special Characters and Stop Word Removal}{13}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Remove special characters and stop words\relax }}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Tokenization and Stemming of the datasets}{14}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Special Character and Stopword Removal with Pandas and NLTK\relax }}{14}\protected@file@percent }
\citation{textclassification}
\citation{scikit-learn}
\citation{tfidf}
\citation{tfidf}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Methodology}{15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{locode}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Vector Representation of the Text}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Term Frequency-Inverse Document Frequency}{15}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces \gls {tfidf} Fitting\relax }}{17}\protected@file@percent }
\citation{gensim}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Top 10 terms by \Gls {tfidf} weight\relax }}{18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Word Embeddings}{18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Word2Vec}{18}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Most similar word to 'trump'\relax }}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Classification Algorithms}{19}\protected@file@percent }
\citation{randomforest}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}SVM}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Multinomial Naive Bayes Classifier}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Random Forest Classifier}{20}\protected@file@percent }
\citation{logisticregression}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Logistic Regression Classifier}{21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Grid Search}{22}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Grid Search Result of the \gls {mnb} Classifier\relax }}{22}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces Grid Search for \gls {mnb} classifier\relax }}{22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Training and Predicting}{22}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {8}{\ignorespaces Classifier fitting\relax }}{23}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Bidirectional Encoder Representations from Transformers}{24}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{locode}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Evaluation}{25}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{locode}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibdata{BA}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{26}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{locode}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibcite{algorithms}{1}
\bibcite{randomforest}{2}
\bibcite{IR-book}{3}
\bibcite{parse}{4}
\bibcite{distributionalhypothesis}{5}
\bibcite{textclassification}{6}
\bibcite{iterparse}{7}
\bibcite{pandas}{8}
\bibcite{scikit-learn}{9}
\bibcite{gensim}{10}
\bibcite{word2vecparam}{11}
\bibcite{tfidf}{12}
\bibcite{logisticregression}{13}
\bibcite{effiecientestimation}{14}
\bibstyle{plain}
